{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ublbUGGBOPU1"
   },
   "source": [
    "-----------------------------\n",
    "## Context:\n",
    "-----------------------------\n",
    "In this case study, we will use the Air pollution dataset which contains information about 13 months of data on major pollutants and meteorological levels of a city. \n",
    "\n",
    "-----------------------------\n",
    "## Objective: \n",
    "-----------------------------\n",
    "The objective of this problem is to reduce the number of features by using dimensionality reduction techniques like PCA and extract insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--TM2FWEOPU4"
   },
   "source": [
    "## Importing libraries and overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK1odb70OPU4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#to scale the data using z-score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Importing PCA and TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUFD5GJPOPVQ"
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data= pd.read_csv(\"Air_Pollution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmccAeSTOPVR",
    "outputId": "a0fe4110-3513-4829-dd2b-67908e734b56"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EfTVX4ZOPVS"
   },
   "source": [
    "#### Check the info of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pYukcobOPVS",
    "outputId": "ebeda551-adcf-4845-e150-4f06265d23e4"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-Jbx8ycOPVT"
   },
   "source": [
    "- There are 403 observations and 27 columns in the data.\n",
    "- All the columns except Date and Weather are of numeric data type.\n",
    "- The Date and SrNo for all observations would be unique. We can drop these columns as they would not add value to our analysis.\n",
    "- Weather is of object data type. We can create dummy variables for each category and convert it to numeric data type.\n",
    "- The majority of the columns have some missing values.\n",
    "- Let's check the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lm3FVIAxOPVT",
    "outputId": "4092c074-7b28-429b-bfa3-5b23fb466dd8"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnmJ-if_OPVU"
   },
   "source": [
    "- All the columns except SrNo and Date have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrGqbeJDOPVU"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kq7M_pDAOPVU"
   },
   "outputs": [],
   "source": [
    "data.drop(columns=[\"SrNo\", \"Date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbzFRLTVOPVV"
   },
   "outputs": [],
   "source": [
    "#Imputing missing values with mode(most frequent) for the Weather column and with median for all other columns\n",
    "for col in data.columns:\n",
    "    if col == \"Weather\":\n",
    "        data[col].fillna(value=data[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        data[col].fillna(value=data[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9U3iDryOPVW"
   },
   "outputs": [],
   "source": [
    "#Creating dummy variables for Weather column\n",
    "data = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6mt96cROPVW"
   },
   "source": [
    "#### Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Define Standard scaler and fit to the data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f-iHotPOPVX"
   },
   "outputs": [],
   "source": [
    "scaler = ________\n",
    "data_scaled = __________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewM1fJZDOPVX"
   },
   "outputs": [],
   "source": [
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrzAdBTkOPVY"
   },
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Define PCA with n components and random_state =1 and fit to the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1T7BATJOPVY"
   },
   "outputs": [],
   "source": [
    "#Defining the number of principal components to generate \n",
    "n = data_scaled.shape[1]\n",
    "\n",
    "#Finding principal components for the data\n",
    "pca1 = PCA(__________)\n",
    "data_pca = pd.DataFrame(pca1._________________)\n",
    "\n",
    "#The percentage of variance explained by each principal component\n",
    "exp_var1 = pca1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GsLRhKuOPVZ",
    "outputId": "ad3e9497-99cd-4387-b546-effbb8ebc47b"
   },
   "outputs": [],
   "source": [
    "# visulaize the explained variance by individual components\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(range(1,29), pca1.explained_variance_ratio_.cumsum(), marker = 'o', linestyle = '--')\n",
    "plt.title(\"Explained Variances by Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: How many Principal components explains more than 70% variance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VW92ZD2OPVZ",
    "outputId": "fd6f6d47-8e0c-4e30-d7f6-60c88f642eaa"
   },
   "outputs": [],
   "source": [
    "# find the least number of components that can explain more than 70% variance\n",
    "sum = 0\n",
    "for ix, i in enumerate(exp_var1):\n",
    "  sum = sum + i\n",
    "  if(sum>________):\n",
    "    print(\"Number of PCs that explain at least 70% variance: \", ix+1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0ClAlbfOPVa"
   },
   "outputs": [],
   "source": [
    "#Making a new dataframe with first 8 principal components and original features as indices\n",
    "cols = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n",
    "\n",
    "pc1 = pd.DataFrame(np.round(pca1.components_.T[:, 0:5],2), index=data_scaled.columns, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Interpret the coefficients of Five principal components from the below dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAOwaQpYzoyO",
    "outputId": "c63de617-cc2d-435e-fe33-f33770654810"
   },
   "outputs": [],
   "source": [
    "def color_high(val):\n",
    "    if val <= -0.25: # you can decide any value as per your understanding\n",
    "        return 'background: pink'\n",
    "    elif val >= 0.25:\n",
    "        return 'background: skyblue'   \n",
    "    \n",
    "pc1.style.applymap(color_high)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "q6mt96cROPVW"
   ],
   "name": "Case Study - PCA and TSNE (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
